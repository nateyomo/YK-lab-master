@article{curran-everett-AssumptionOfNormality2017,
  title = {Explorations in Statistics: The Assumption of Normality},
  shorttitle = {Explorations in Statistics},
  author = {{Curran-Everett}, Douglas},
  year = {2017},
  month = sep,
  journal = {Advances in Physiology Education},
  volume = {41},
  number = {3},
  pages = {449--453},
  issn = {1522-1229},
  doi = {10.1152/advan.00064.2017},
  abstract = {Learning about statistics is a lot like learning about science: the learning is more meaningful if you can actively explore. This twelfth installment of Explorations in Statistics explores the assumption of normality, an assumption essential to the meaningful interpretation of a t test. Although the data themselves can be consistent with a normal distribution, they need not be. Instead, it is the theoretical distribution of the sample mean or the theoretical distribution of the difference between sample means that must be roughly normal. The most versatile approach to assess normality is to bootstrap the sample mean, the difference between sample means, or t itself. We can then assess whether the distributions of these bootstrap statistics are consistent with a normal distribution by studying their normal quantile plots. If we suspect that an inference we make from a t test may not be justified-if we suspect that the theoretical distribution of the sample mean or the theoretical distribution of the difference between sample means is not normal-then we can use a permutation method to analyze our data.},
  langid = {english},
  pmid = {28743689},
  keywords = {bootstrap,Central Limit Theorem,Data Interpretation Statistical,Models Statistical,normal quantile plot,permutation methods,To Read},
  file = {/Users/nathanielyomogida/Zotero/storage/A4IZLQIC/Curran-Everett (2017) Explorations in statistics.pdf}
}

@article{curran-everettLogTransformation2018,
  title = {Explorations in Statistics: The Log Transformation},
  shorttitle = {Explorations in Statistics},
  author = {{Curran-Everett}, Douglas},
  year = {2018},
  month = jun,
  journal = {Advances in Physiology Education},
  volume = {42},
  number = {2},
  pages = {343--347},
  issn = {1522-1229},
  doi = {10.1152/advan.00018.2018},
  abstract = {Learning about statistics is a lot like learning about science: the learning is more meaningful if you can actively explore. This thirteenth installment of Explorations in Statistics explores the log transformation, an established technique that rescales the actual observations from an experiment so that the assumptions of some statistical analysis are better met. A general assumption in statistics is that the variability of some response Y is homogeneous across groups or across some predictor variable X. If the variability-the standard deviation-varies in rough proportion to the mean value of Y, a log transformation can equalize the standard deviations. Moreover, if the actual observations from an experiment conform to a skewed distribution, then a log transformation can make the theoretical distribution of the sample mean more consistent with a normal distribution. This is important: the results of a one-sample t test are meaningful only if the theoretical distribution of the sample mean is roughly normal. If we log-transform our observations, then we want to confirm the transformation was useful. We can do this if we use the Box-Cox method, if we bootstrap the sample mean and the statistic t itself, and if we assess the residual plots from the statistical model of the actual and transformed sample observations.},
  langid = {english},
  pmid = {29761718},
  keywords = {bootstrap,Central Limit Theorem,Data Collection,Humans,Linear Models,Models Statistical,normal quantile plot,Physiology,residual plots,To Read},
  file = {/Users/nathanielyomogida/Zotero/storage/8GUL46X7/Curran-Everett (2018) Explorations in statistics.pdf}
}
